{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition: Predicting Red Hat Business Value\n",
    "## Define the problem: Classify customer potential\n",
    "Like most companies, Red Hat is able to gather a great deal of information over time about the behavior of individuals who interact with them. They’re in search of better methods of using this behavioral data to predict which individuals they should approach—and even when and how to approach them.\n",
    "\n",
    "**What is the problem? (include similar problems and assumptions)** <br>\n",
    "In this competition, Kagglers are challenged to create a classification algorithm that accurately identifies which customers have the most potential business value for Red Hat based on their characteristics and activities.\n",
    "\n",
    "**Why does the problem need to be solved?** <br>\n",
    "With an improved prediction model in place, Red Hat will be able to more efficiently prioritize resources to generate more business and better serve their customers.\n",
    "\n",
    "The challenge of this competition is to predict the potential business value of a person who has performed a specific activity. The business value outcome is defined by a yes/no field attached to each unique activity in the activity file. The outcome field indicates whether or not each person has completed the outcome within a fixed window of time after each unique activity was performed.\n",
    "\n",
    "**How could the problem be solved (manually brainstorm potential approaches)** <br>\n",
    "TBC\n",
    "\n",
    "## Data \n",
    "**Explain the data available (What is/is'nt needed)** <br>\n",
    "This competition uses two separate data files that may be joined together to create a single, unified data table: a people file and an activity file.\n",
    "\n",
    "The people file contains all of the unique people (and the corresponding characteristics) that have performed activities over time. Each row in the people file represents a unique person. Each person has a unique people_id.\n",
    "\n",
    "The activity file contains all of the unique activities (and the corresponding activity characteristics) that each person has performed over time. Each row in the activity file represents a unique activity performed by a person on a certain date. Each activity has a unique activity_id.\n",
    "\n",
    "The activity file contains several different categories of activities. Type 1 activities are different from type 2-7 activities because there are more known characteristics associated with type 1 activities (nine in total) than type 2-7 activities (which have only one associated characteristic).\n",
    "\n",
    "To develop a predictive model with this data, you will likely need to join the files together into a single data set. The two files can be joined together using person_id as the common key. All variables are categorical, with the exception of 'char_38' in the people file, which is a continuous numerical variable.\n",
    "\n",
    "## Evaluation Criteria\n",
    "For each activity_id in the test set, you must predict a probability for the 'outcome' variable, represented by a number between 0 and 1\n",
    "Evaluated on area under the ROC curve between the predicted and the observed outcome\n",
    "\n",
    "### Reference\n",
    "https://www.kaggle.com/c/predicting-red-hat-business-value/data <br>\n",
    "https://machinelearningmastery.com/machine-learning-checklist/ <br>\n",
    "https://machinelearningmastery.com/process-for-working-through-machine-learning-problems/ <br> \n",
    "https://medium.com/swlh/framework-for-creating-value-with-ai-6c6d5bb5ff42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/Rej1992/Documents/kaggle/Data/predicting-red-hat-business-value/act_train.csv')\n",
    "test_data = pd.read_csv('/Users/Rej1992/Documents/kaggle/Data/predicting-red-hat-business-value/act_test.csv')\n",
    "people = pd.read_csv('/Users/Rej1992/Documents/kaggle/Data/predicting-red-hat-business-value/people.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outcome']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncommon_elements(test_data.columns, train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process: data preparation, data transforms, model selection, model tuning, ensemlbing and so on is a combinatorial problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing (Data Preparation) <br>\n",
    "Describe in detail each attribute and relationships between attributes. This grunt work forces thought about the data in the context of the problem before it is lost to the algorithms\n",
    "- Format data so that it is in a form that you can work with.\n",
    "- Clean the data so that it is uniform and consistent.\n",
    "- Representatively sample the data rows and select attributes that best expose the structures in the data to the models in order to best trade-off redundancy and problem fidelity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transforms\n",
    "- Create linear and non-linear transformations of all attributes\n",
    "- Decompose complex attributes into their constituent parts.\n",
    "- Aggregate denormalized attributes into higher-order quantities.\n",
    "- Common transforms (Square, Cube, Square root, Standardize (e.g. 0 mean and unit variance), Normalize (e.g. rescale to 0-1), Descritize (e.g. convert a real to categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "Develop a set of hypothesis's to test that should hold in the real world - Validate does the data make sense?\n",
    "- Create univariate plots of each attribute.\n",
    "- Create bivariate plots of each attribute with every other attribute.\n",
    "- Create bivariate plots of each attribute with the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Development and Selection\n",
    "- Create Test Harness\n",
    "    - This section is intended to help you define a robust method for model evaluation that can reliably be used to compare results.\n",
    "    - Create a hold-out validation dataset for use later.\n",
    "    = Select a cross-validation strategy (which datasets perform the best? Why?)\n",
    "    - Evaluate and select an appropriate test option.\n",
    "    - Select one (or a small set) performance measure used to evaluate models.\n",
    "- Evalute Multiple (suitable) Model Candidates and select the most promising candidates\n",
    "    - Use statistical significance tests to flush out meaningful results from noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Improvements\n",
    "- Model tuning\n",
    "- Ensemlbing Methods\n",
    "- Model Selection\n",
    "    - Select a diverse subset (5-10) of well performing models or model configurations.\n",
    "    - Evaluate well performing models on a hold out validation dataset (running an automated sensitivity analysis on the parameters of the top performing algorithms)\n",
    "    - Select a small pool (1-3) of well performing models.\n",
    "    - Include statistical tests to validate and support arguments in relation to model improvement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalise the Project\n",
    "- Decision Record\n",
    "- Present Results\n",
    "    - This section is intended to ensure you capture what you did and learned so that others (and your future self) can make best use of it\n",
    "    - Write up project in a short report (1-5 pages).\n",
    "    - Convert write-up to a slide deck to share findings with others.\n",
    "    - Share code and results with interested parties.\n",
    "\n",
    "- Operationalize Results\n",
    "    - This section is intended to ensure that you deliver on the solution promise made up front.\n",
    "    - Adapt the discovered procedure from raw data to result to an operational setting.\n",
    "    - Deliver and make use of the predictions.\n",
    "    - Deliver and make use of the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
